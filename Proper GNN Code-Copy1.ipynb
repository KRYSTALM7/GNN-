{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd9186ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4be731a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sensor_00  sensor_01  sensor_02  sensor_03  sensor_04  sensor_05  \\\n",
      "0   2.465394   47.09201    53.2118  46.310760   634.3750   76.45975   \n",
      "1   2.465394   47.09201    53.2118  46.310760   634.3750   76.45975   \n",
      "2   2.444734   47.35243    53.2118  46.397570   638.8889   73.54598   \n",
      "3   2.460474   47.09201    53.1684  46.397568   628.1250   76.98898   \n",
      "4   2.445718   47.13541    53.2118  46.397568   636.4583   76.58897   \n",
      "\n",
      "   sensor_06  sensor_07  sensor_08  sensor_09  ...  sensor_44  sensor_45  \\\n",
      "0   13.41146   16.13136   15.56713   15.05353  ...  39.641200   65.68287   \n",
      "1   13.41146   16.13136   15.56713   15.05353  ...  39.641200   65.68287   \n",
      "2   13.32465   16.03733   15.61777   15.01013  ...  39.351852   65.39352   \n",
      "3   13.31742   16.24711   15.69734   15.08247  ...  39.062500   64.81481   \n",
      "4   13.35359   16.21094   15.69734   15.08247  ...  38.773150   65.10416   \n",
      "\n",
      "   sensor_46  sensor_47  sensor_48  sensor_49  sensor_50  sensor_51  \\\n",
      "0   50.92593  38.194440   157.9861   67.70834   243.0556   201.3889   \n",
      "1   50.92593  38.194440   157.9861   67.70834   243.0556   201.3889   \n",
      "2   51.21528  38.194443   155.9606   67.12963   241.3194   203.7037   \n",
      "3   51.21528  38.194440   155.9606   66.84028   240.4514   203.1250   \n",
      "4   51.79398  38.773150   158.2755   66.55093   242.1875   201.3889   \n",
      "\n",
      "   machine_status                 date  \n",
      "0          NORMAL  2018-04-01 00:00:00  \n",
      "1          NORMAL  2018-04-01 00:01:00  \n",
      "2          NORMAL  2018-04-01 00:02:00  \n",
      "3          NORMAL  2018-04-01 00:03:00  \n",
      "4          NORMAL  2018-04-01 00:04:00  \n",
      "\n",
      "[5 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(r'C:\\Users\\SUJAN\\preprocessed_data.csv')  \n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b308853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build a graph representation\n",
    "num_sensors = df.shape[1] - 2  # Subtracting 2 to exclude 'machine_status' and 'date' columns\n",
    "adjacency_matrix = np.ones((num_sensors, num_sensors))  # Fully connected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd7bf495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Print the adjacency matrix\n",
    "print(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "504b6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Graph Convolutional Network (GCN) model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0531a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 6: Train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AnomalyDetectionModel(input_dim=4, hidden_dim=64).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4599d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the adjacency matrix to PyTorch tensors\n",
    "edge_index = torch.tensor(np.vstack(np.nonzero(adjacency_matrix)), dtype=torch.long).to(device)\n",
    "x = torch.tensor(X, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ccfe965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and labels\n",
    "exclude_columns = ['machine_status', 'date']\n",
    "X = df.drop(columns=exclude_columns).values\n",
    "y = torch.tensor(df['machine_status'].map({'NORMAL': 0, 'BROKEN': 1, 'RECOVERING': 1}).values, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbcd0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GCN model\n",
    "input_dim = X.shape[1]\n",
    "hidden_dim = 64\n",
    "output_dim = 1  # Output dimension for anomaly detection (binary classification)\n",
    "model = GCN(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3bda8ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out, data.y.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f98e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            out = model(data.x, data.edge_index)\n",
    "            predicted = torch.sigmoid(out) > 0.5\n",
    "            predicted_labels.extend(predicted.squeeze().tolist())\n",
    "            true_labels.extend(data.y.tolist())\n",
    "\n",
    "    predicted_labels = torch.tensor(predicted_labels, dtype=torch.float32)  # Convert to tensor\n",
    "    true_labels = torch.tensor(true_labels, dtype=torch.float32)  # Convert to tensor\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a36ea931",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predicted_labels.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "724027b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[205836      0]\n",
      " [     0  14484]]\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Convert the predicted labels and true labels to numpy arrays\n",
    "predicted_labels = predicted_labels.squeeze()\n",
    "true_labels = dataset.y.cpu().numpy()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "confusion_mat = confusion_matrix(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels)\n",
    "recall = recall_score(true_labels, predicted_labels)\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "62fb5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(len(df.columns)):\n",
    "    plt.subplot(len(df.columns), 1, i+1)\n",
    "    plt.plot(test_data[:, i], label='Original Data', color='blue')\n",
    "    plt.plot(test_output[:, i], label='Predicted Data', color='green')\n",
    "    plt.scatter(torch.nonzero(anomaly_mask[:, i]).squeeze().tolist(), test_output[:, i][anomaly_mask[:, i]].squeeze().tolist(),\n",
    "                color='red', label='Anomalies')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "plt.suptitle('GNN Anomaly Detection')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the anomaly detection results\n",
    "if torch.any(anomaly_mask):\n",
    "    print(\"Anomalies detected!\")\n",
    "    print(\"Anomaly indices:\")\n",
    "    for i in range(len(df.columns)):\n",
    "        print(f\"Variable {df.columns[i]}:\", torch.nonzero(anomaly_mask[:, i]).squeeze().tolist())\n",
    "else:\n",
    "    print(\"No anomalies detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "73241d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56125c85",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'anomaly_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_graph_with_anomalies(G, \u001b[43manomaly_mask\u001b[49m, df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'anomaly_mask' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc573a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
