{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c8b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SYNTHETIC CORRELATED DATA GENERATION ###\n",
    "\n",
    "np.random.seed(33)\n",
    "\n",
    "n_features = 50\n",
    "n_samples = 4_000\n",
    "\n",
    "r = np.random.randint(-2,10, (n_features,n_features))\n",
    "r = np.dot(r, r.T)\n",
    "\n",
    "x = np.random.normal(0,1, (n_features,n_samples))\n",
    "c = np.linalg.cholesky(r)\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    np.dot(c, x).T, columns=[f\"feat_{c+1}\" for c in range(n_features)]\n",
    ")\n",
    "\n",
    "corr_mat = pairwise_distances(X.T, metric='correlation')\n",
    "\n",
    "X.shape, corr_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b840ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT SERIES DISTRIBUTIONS ###\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(1,2,1)\n",
    "X.plot(legend=False, xlabel='timesteps', ax=plt.gca())\n",
    "plt.subplot(1,2,2)\n",
    "X.plot(kind='density', legend=False, ax=plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c809a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT SERIES CORRELATIONS ###\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(X.corr(), annot=False, cmap='bwr')\n",
    "plt.title('correlation matrix')\n",
    "plt.ylabel('series'); plt.xlabel('series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26f439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MANUALLY INSERT ANOMALOUS PERIOD ###\n",
    "\n",
    "n_samples_change = 400\n",
    "_ = np.random.randint(0,n_samples-n_samples_change)\n",
    "\n",
    "X.loc[np.arange(_, _+n_samples_change), 'feat_2'] = \\\n",
    "    np.random.normal(X['feat_2'].mean(), X['feat_2'].std(), (n_samples_change,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PCA ANOMALY DETECTION ###\n",
    "\n",
    "rec_errors_samples = {}\n",
    "rec_errors_features = {}\n",
    "\n",
    "for i, (past_id,future_id) in enumerate(\n",
    "    TimeSeriesSplit(10, test_size=300).split(X)\n",
    "):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA(0.7, random_state=33)\n",
    "    pca.fit(scaler.fit_transform(X.iloc[past_id]))\n",
    "    \n",
    "    Xt = pca.inverse_transform(\n",
    "        pca.transform(\n",
    "            scaler.transform(X.iloc[future_id])\n",
    "        )\n",
    "    )\n",
    "    rec_errors_samples[past_id[-1]] = \\\n",
    "        np.linalg.norm(scaler.transform(X.iloc[future_id]) - Xt, axis=1)\n",
    "    rec_errors_features[past_id[-1]] = \\\n",
    "        np.linalg.norm(scaler.transform(X.iloc[future_id]) - Xt, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a2e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT PCA RECONSTRUCTION ERRORS ###\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(list(rec_errors_samples.keys()), \n",
    "         [np.mean(r) for r in rec_errors_samples.values()])\n",
    "plt.ylabel('recontruction error'); plt.xlabel('timesteps')\n",
    "plt.title('sample-wise recontruction')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "for i in range(n_features):\n",
    "    rec = []\n",
    "    for r in rec_errors_features.values():\n",
    "        rec.append(r[i])\n",
    "    plt.plot(list(rec_errors_features.keys()), rec)\n",
    "plt.ylabel('recontruction error'); plt.xlabel('timesteps')\n",
    "plt.title('feature-wise recontruction')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPUTE HIERARCHICAL CLUSTERING ON CORRELATION MATRIX ###\n",
    "\n",
    "d = sch.distance.pdist(corr_mat)\n",
    "L = sch.linkage(d, method='ward')\n",
    "ind = sch.fcluster(L, d.max(), 'distance')\n",
    "dendrogram = sch.dendrogram(L, no_plot=True)\n",
    "\n",
    "labels = dendrogram['leaves']\n",
    "corr_mat_cluster = pairwise_distances(\n",
    "    pd.concat([X.iloc[:,[i]] for i in labels], axis=1).T,\n",
    "    metric='correlation'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.subplot(1,2,1)\n",
    "dendrogram = sch.dendrogram(L, no_plot=False)\n",
    "plt.title('dendrogram')\n",
    "plt.ylabel('distance'); plt.xlabel('series')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(corr_mat_cluster, cmap='bwr')\n",
    "plt.title('correlation matrix')\n",
    "plt.ylabel('series'); plt.xlabel('series')\n",
    "plt.xticks(range(n_features), labels, rotation=90)\n",
    "plt.yticks(range(n_features), labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87f43dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DBSCAN ANOMALY DETECTION ###\n",
    "\n",
    "network_ano = {}\n",
    "dbscan = DBSCAN(eps=0.6, min_samples=1, metric=\"precomputed\")\n",
    "\n",
    "for i, (past_id,_) in enumerate(\n",
    "    TimeSeriesSplit(10, test_size=300, max_train_size=300).split(X)\n",
    "):\n",
    "    \n",
    "    preds = dbscan.fit_predict(\n",
    "        pairwise_distances(X.iloc[past_id].T, metric='correlation')\n",
    "    )\n",
    "    if (preds > 0).any():\n",
    "        ano_features = list(X.columns[np.where(preds > 0)[0]])\n",
    "        network_ano[past_id[-1]] = ano_features\n",
    "    else:\n",
    "        network_ano[past_id[-1]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4163898",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT DBSCAN DETECTED ANOMALIES ###\n",
    "\n",
    "roll_corr = X.rolling(300).corr()\n",
    "\n",
    "for ano_loc,ano in network_ano.items():\n",
    "    if ano is not None:\n",
    "        for ano_feat in network_ano[ano_loc]:\n",
    "            roll_corr[ano_feat].unstack().plot(\n",
    "                legend=False, figsize=(11,6),\n",
    "                title=f\"{ano_feat} rolling correlation\",\n",
    "                ylabel='correlation', xlabel='timesteps'\n",
    "            )\n",
    "            plt.axvline(ano_loc, linestyle='--', c='black')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b8923f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
